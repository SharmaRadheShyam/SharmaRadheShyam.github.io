<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Academics</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Vinod Kumar Kurmi</div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Progress Report</h1>
</div>
<h2>Task Done </h2>

<ul>
</li>
<li><p> 1. Trained a basic CNN model for classification and feature extraction using CIFAR dataset(~20 July- 25 July)[<a href="http://people.eecs.berkeley.edu/~sgupta/pdf/hallucination.pdf">Link</a>}</p>
</li>
<li><p> 2. Trained a CNN model channel wise using CIFAR dataset (~21 July- 31 July).[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>
</li>
<li><p> 3. Experiment with Gaussian Process for Modality Hallucination with CNN features (Term Paper Work revised)(~01 Aug- 05 Aug).[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>
</li>
<li><p> 4. Train a Gaussian Process regression model on any arbitary data for regreting or  hallucination other data(used Torch)(~06 Aug- 14 Aug).[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>
</li>
<li><p> 5. Trained a Context Encoder model for generating the image from CNN features(~22 Aug-10 Sep).[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>
</li>
<li><p> 6. Trained channel wise a Context Encoder model and generate the channel wise images from there CNN features(11 Sep-12 Sep).[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>
</li>
<li><p> 7. Tained d GP for hallucinating one channel features from the other one(~12sep-15 Sep).[<a href="http://home.iitk.ac.in/~vinodkk/progress/gp_cifar">Link</a>]</p>
</li>
<li><p> 8. Generate the images from the feature that are hallucinated (~12sep-15 Sep).[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>

</li>
<li><p> 9. Read the Transfer Learning paper for classfication task  (~).[<a href= "https://arxiv.org/pdf/1409.7495v2.pdf">Paper1 Link</a>] [<a href= "http://cs.stanford.edu/~jhoffman/papers/Tzeng_ICCV2015.pdf">Paper 2 Link</a>]</p>
</li>
<li><p> 10. Analyse the Encoder Decoder code that can be used as a transfer learning for domain identification.  (~).
</li>
<li><p> 11. Dataset creation for transfer learning.[<a href="http://home.iitk.ac.in/~vinodkk/progress/transfer-learning_dataset-creation">Link</a>]</p>

</li>
<li><p> 12. Image generation check for dataset created for the tranfer learning problem.

</li>
</ul>

<h2>Paper Reading</h2>
<p> Relavant Papers<br />

<ul>
</li>
<li><p>Learning to recognize objects from unseen modalities[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15549-9_49#page-1">Link</a>]</p>
</li>
<li><p>Context Encoders: Feature Learning by Inpainting [<a href="http://people.eecs.berkeley.edu/~pathak/papers/cvpr16.pdf">Link</a>][<a href="https://github.com/pathak22/context-encoder">Code</a> ]</p>
</li>
<li><p>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[<a href="https://arxiv.org/pdf/1511.06434.pdf">Link</a>]</p>
</li>
<li><p>Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification[<a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/">Link</a>]</p>

</li>
<li><p>Image Recoloarization for the colorblind [<a href="http://www.iis.sinica.edu.tw/papers/song/10618-F.pdf">Link</a>]</p>
</li>
<li><p>Removal of Color Blindness using Threshold and Masking[<a href="https://www.ijarcsse.com/docs/papers/Volume_3/6_June2013/V3I6-0258.pdf">Link</a>]</p>
</li>
<li><p>Unsupervised Domain Adaptation by Backpropagation [<a href= "https://arxiv.org/pdf/1409.7495v2.pdf">Link</a>] </p>
</li>
<li><p>Simultaneous Deep Transfer Across Domains and Tasks [<a href= "http://cs.stanford.edu/~jhoffman/papers/Tzeng_ICCV2015.pdf"> Link</a>] </p>
</li>
<li><p>Basic about the deconvolution layer  [<a href= "https://arxiv.org/ftp/arxiv/papers/1609/1609.07009.pdf"> Link</a>] </p>

</li>

</ul>



<h2>Next Step</h2>

<ul>
</li>
<li><p> End to End Training using GAN for RGB and simulate protanopia images(using the <a href="http://vision.psychol.cam.ac.uk/jdmollon/papers/Dichromat_simulation.pdf">paper</a> ) along withe re-colored images.[<a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/">Link</a>]</p>
</li>
<li><p>Add more dataset features for training the Gaussian Process  </p>
</li>
<li><p>Hallucinating using the cross modality model by Saurav Gupta's paper [<a href="http://people.eecs.berkeley.edu/~sgupta/pdf/hallucination.pdf">Link</a>]</p>
</li>
<li><p>Like colorization based paper combine only the halluciantion features in the orignal image rather then decoding it from the features[<a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/">Link</a>]</p>

</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2014-12-18 03:15:16 India Standard Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59640726-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
